{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate a transcriptome with TE transcripts using polyester\n",
    "\n",
    "1. Generate transcriptome \n",
    " - Spliced and unspliced transcripts from GENCODE annotation\n",
    " - L1 transcripts from full-length L1HS-L1PA6 annotations in reference genome\n",
    " OR\n",
    " - L1 consensus sequences from RepBase (ask mike for file)\n",
    "\n",
    "2. Simulate reads with polyester (see code from `./mikes_old_notebook`)\n",
    "3. Quantify reads with salmon\n",
    " - build index of transcriptome (use same transcriptome from step 1)\n",
    " - quantify reads with salmon\n",
    "\n",
    "4. Compare with original count matrix\n",
    " - figure out how to get read counts from salmon (https://salmon.readthedocs.io/en/latest/file_formats.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pyranges as pr\n",
    "from Bio import SeqIO\n",
    "from src.make_txome import make_txome\n",
    "from src.simulate import run_polyester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set outdir\n",
    "OUTDIR = Path(\"../results/20231004_benchmark/\")\n",
    "OUTDIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating transcriptome "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get L1 transcripts from annotations in reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parsed rmsk file\n",
    "# NOTE: ignore has_promoter column for now, not sure if it is accurate\n",
    "rmsk = pd.read_csv(\"../resources/hg38.rmsk.tsv\", sep=\"\\t\")\n",
    "rmsk = rmsk[(rmsk.repName == \"L1HS\") & (rmsk.length > 6000)]\n",
    "rmsk = rmsk[[\"genoName\", \"genoStart\", \"genoEnd\", \"strand\"]].rename(\n",
    "    columns={\n",
    "        \"genoName\": \"Chromosome\",\n",
    "        \"genoStart\": \"Start\",\n",
    "        \"genoEnd\": \"End\",\n",
    "        \"strand\": \"Strand\",\n",
    "    }\n",
    ")\n",
    "rmsk = rmsk[rmsk.Chromosome == \"chr22\"]\n",
    "\n",
    "# save as bedfile\n",
    "L1_BED = \"../resources/hg38_FL_L1HS.bed\"\n",
    "pr.PyRanges(rmsk).to_bed(L1_BED)\n",
    "\n",
    "# use bedfile to extract sequences from fasta, save to new fasta\n",
    "GENOME_FA = \"../resources/hg38.fa\"\n",
    "L1_FA = \"../resources/hg38_FL_L1HS.fa\"\n",
    "!bedtools getfasta -s -fi {GENOME_FA} -bed {L1_BED} -fo {L1_FA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src.make_txome: 10-24 14:02:31] {139748869257024} INFO - Using bedtools from /logg/LOG-G4/mcuoco/projects/bulk_te_bench/.conda/bin/bedtools\n",
      "INFO:src.make_txome:Using bedtools from /logg/LOG-G4/mcuoco/projects/bulk_te_bench/.conda/bin/bedtools\n",
      "INFO:src.make_txome:Using bedtools from /logg/LOG-G4/mcuoco/projects/bulk_te_bench/.conda/bin/bedtools\n",
      "[src.make_txome: 10-24 14:02:54] {139748869257024} INFO - Chromosome chr22 fasta written to /iblm/netapp/data4/mcuoco/tmp/tmp_2x2cflc.fa\n",
      "INFO:src.make_txome:Chromosome chr22 fasta written to /iblm/netapp/data4/mcuoco/tmp/tmp_2x2cflc.fa\n",
      "[src.make_txome: 10-24 14:03:37] {139748869257024} INFO - Chromosome chr22 gtf written to /iblm/netapp/data4/mcuoco/tmp/tmppery4_1h.gtf\n",
      "INFO:src.make_txome:Chromosome chr22 gtf written to /iblm/netapp/data4/mcuoco/tmp/tmppery4_1h.gtf\n",
      "[src.make_txome: 10-24 14:03:37] {139748869257024} INFO - Saving spliceu txome to ../results/20231004_benchmark/chr22_txome\n",
      "INFO:src.make_txome:Saving spliceu txome to ../results/20231004_benchmark/chr22_txome\n",
      "WARNING:root: Found gene(s) without exons; Ignored.\n",
      "WARNING:root: Found genes whose boundaries defined in the gene feature records do not equal to their exons' bounds. However, those boundaries were still used to extract unspliced sequences.\n",
      "WARNING:root: A clean GTF file with all issues fixed is generated at ../results/20231004_benchmark/chr22_txome/clean_gtf.gtf. If needed, please rerun using this clean GTF file.\n"
     ]
    }
   ],
   "source": [
    "### Generating transcriptome\n",
    "# - use the code from make_txome to make a gtf file with the L1 annotations\n",
    "TXOME_GTF = \"../resources/gencode.v44.primary_assembly.basic.annotation.gtf\"\n",
    "make_txome(OUTDIR / \"chr22_txome\", GENOME_FA, TXOME_GTF, L1_FA, chromosome=\"chr22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update gene map\n",
    "t2g_3col = pd.read_csv(OUTDIR / \"chr22_txome/txome_t2g_3col.tsv\", sep=\"\\t\", header=None)\n",
    "t2g_3col[1] = t2g_3col[1].apply(lambda x: \"L1HS\" if \"chr\" in x else x)\n",
    "t2g_3col.iloc[:, :2].to_csv(\n",
    "    OUTDIR / \"chr22_txome/txome_t2g.tsv\", sep=\"\\t\", header=None, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate reads with polyester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXOME_FA = OUTDIR / \"chr22_txome/txome.fa\"\n",
    "\n",
    "# make count matrix to simulate from\n",
    "# ~20x coverage ----> reads per transcript = transcriptlength/readlength * 20\n",
    "# here all transcripts will have ~equal FPKM\n",
    "# read length = 100\n",
    "counts = defaultdict(list)\n",
    "for tx in SeqIO.parse(TXOME_FA, \"fasta\"):\n",
    "    counts[\"tx_id\"].append(tx.id)\n",
    "    for sample in range(0, 3):\n",
    "        if \"ENS\" in tx.id:\n",
    "            counts[sample].append(20 * len(tx.seq) // 100)\n",
    "        elif \"chr\" in tx.id:\n",
    "            counts[sample].append(sample * len(tx.seq) // 100)\n",
    "        else:\n",
    "            counts[sample].append(0)\n",
    "\n",
    "counts = pd.DataFrame(counts).set_index(\"tx_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src.simulate: 10-24 14:03:43] {139748869257024} INFO - Simulating reads from 4002 transcripts from 3 samples with polyester\n",
      "INFO:src.simulate:Simulating reads from 4002 transcripts from 3 samples with polyester\n",
      "INFO:src.simulate:Simulating reads from 4002 transcripts from 3 samples with polyester\n",
      "[Parallel(n_jobs=32)]: Using backend MultiprocessingBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done   5 out of  32 | elapsed:  1.1min remaining:  6.1min\n",
      "[Parallel(n_jobs=32)]: Done   9 out of  32 | elapsed:  1.4min remaining:  3.7min\n",
      "[Parallel(n_jobs=32)]: Done  13 out of  32 | elapsed:  1.6min remaining:  2.4min\n",
      "[Parallel(n_jobs=32)]: Done  17 out of  32 | elapsed:  1.9min remaining:  1.7min\n",
      "[Parallel(n_jobs=32)]: Done  21 out of  32 | elapsed:  2.6min remaining:  1.3min\n",
      "[Parallel(n_jobs=32)]: Done  25 out of  32 | elapsed:  9.4min remaining:  2.6min\n",
      "[Parallel(n_jobs=32)]: Done  29 out of  32 | elapsed: 12.5min remaining:  1.3min\n",
      "[Parallel(n_jobs=32)]: Done  32 out of  32 | elapsed: 16.3min finished\n",
      "[src.simulate: 10-24 14:20:03] {139748869257024} INFO - Merging simulated reads\n",
      "INFO:src.simulate:Merging simulated reads\n"
     ]
    }
   ],
   "source": [
    "run_polyester(TXOME_FA, counts, n_jobs=32, outdir=OUTDIR / \"chr22_reads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Server Response: Not Found\n",
      "index [\"../results/20231004_benchmark/chr22_txome_index\"] did not previously exist  . . . creating it\n",
      "[2023-10-24 14:21:21.610] [jLog] [warning] The salmon index is being built without any decoy sequences.  It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode.\n",
      "[2023-10-24 14:21:21.610] [jLog] [info] building index\n",
      "out : ../results/20231004_benchmark/chr22_txome_index\n",
      "\u001b[00m[2023-10-24 14:21:21.612] [puff::index::jointLog] [info] Running fixFasta\n",
      "\u001b[00m\n",
      "[Step 1 of 4] : counting k-mers\n",
      "\u001b[35m[2023-10-24 14:21:22.138] [puff::index::jointLog] [warning] Entry with header [ENSG00000054611.14-I] was longer than 400000 nucleotides.  This is probably a chromosome instead of a transcript.\n",
      "\u001b[00m\u001b[35m[2023-10-24 14:21:22.446] [puff::index::jointLog] [warning] Entry with header [ENSG00000100154.15-I] was longer than 400000 nucleotides.  This is probably a chromosome instead of a transcript.\n",
      "\u001b[00m\u001b[35m[2023-10-24 14:21:22.526] [puff::index::jointLog] [warning] Entry with header [ENSG00000185666.16-I] was longer than 400000 nucleotides.  This is probably a chromosome instead of a transcript.\n",
      "\u001b[00m\u001b[35m[2023-10-24 14:21:22.546] [puff::index::jointLog] [warning] Entry with header [ENSG00000133424.22-I] was longer than 400000 nucleotides.  This is probably a chromosome instead of a transcript.\n",
      "\u001b[00m\n",
      "\u001b[35m[2023-10-24 14:21:22.716] [puff::index::jointLog] [warning] Removed 501 transcripts that were sequence duplicates of indexed transcripts.\n",
      "\u001b[00m\u001b[35m[2023-10-24 14:21:22.716] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:22.719] [puff::index::jointLog] [info] Replaced 50,000 non-ATCG nucleotides\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:22.719] [puff::index::jointLog] [info] Clipped poly-A tails from 16 transcripts\n",
      "\u001b[00mwrote 3501 cleaned references\n",
      "\u001b[00m[2023-10-24 14:21:22.917] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:23.274] [puff::index::jointLog] [info] ntHll estimated 22634793 distinct k-mers, setting filter size to 2^29\n",
      "\u001b[00mThreads = 2\n",
      "Vertex length = 31\n",
      "Hash functions = 5\n",
      "Filter size = 536870912\n",
      "Capacity = 2\n",
      "Files: \n",
      "../results/20231004_benchmark/chr22_txome_index/ref_k31_fixed.fa\n",
      "--------------------------------------------------------------------------------\n",
      "Round 0, 0:536870912\n",
      "Pass\tFilling\tFiltering\n",
      "1\t5\t9\t\n",
      "2\t1\t0\n",
      "True junctions count = 167043\n",
      "False junctions count = 217839\n",
      "Hash table size = 384882\n",
      "Candidate marks count = 1996039\n",
      "--------------------------------------------------------------------------------\n",
      "Reallocating bifurcations time: 0\n",
      "True marks count: 1590105\n",
      "Edges construction time: 2\n",
      "--------------------------------------------------------------------------------\n",
      "Distinct junctions = 167043\n",
      "\n",
      "TwoPaCo::buildGraphMain:: allocated with scalable_malloc; freeing.\n",
      "TwoPaCo::buildGraphMain:: Calling scalable_allocation_command(TBBMALLOC_CLEAN_ALL_BUFFERS, 0);\n",
      "allowedIn: 26\n",
      "Max Junction ID: 167596\n",
      "seen.size():1340777 kmerInfo.size():167597\n",
      "approximateContigTotalLength: 13018717\n",
      "counters for complex kmers:\n",
      "(prec>1 & succ>1)=32066 | (succ>1 & isStart)=9 | (prec>1 & isEnd)=9 | (isStart & isEnd)=2\n",
      "contig count: 272917 element count: 30839160 complex nodes: 32086\n",
      "# of ones in rank vector: 272916\n",
      "\u001b[00m[2023-10-24 14:21:42.861] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:42.861] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory ../results/20231004_benchmark/chr22_txome_index\n",
      "\u001b[00msize = 30839160\n",
      "-----------------------------------------\n",
      "| Loading contigs | Time = 17.421 ms\n",
      "-----------------------------------------\n",
      "size = 30839160\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 2.9889 ms\n",
      "-----------------------------------------\n",
      "Number of ones: 272916\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 534\n",
      "272916\n",
      "\u001b[00m[2023-10-24 14:21:42.931] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:42.935] [puff::index::jointLog] [info] contig count for validation: 272,916\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.033] [puff::index::jointLog] [info] Total # of Contigs : 272,916\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.033] [puff::index::jointLog] [info] Total # of numerical Contigs : 272,916\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.039] [puff::index::jointLog] [info] Total # of contig vec entries: 1,682,464\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.039] [puff::index::jointLog] [info] bits per offset entry 21\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.080] [puff::index::jointLog] [info] Done constructing the contig vector. 272917\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.213] [puff::index::jointLog] [info] # segments = 272,916\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.213] [puff::index::jointLog] [info] total length = 30,839,160\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.219] [puff::index::jointLog] [info] Reading the reference files ...\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.395] [puff::index::jointLog] [info] positional integer width = 25\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.395] [puff::index::jointLog] [info] seqSize = 30,839,160\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.395] [puff::index::jointLog] [info] rankSize = 30,839,160\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.395] [puff::index::jointLog] [info] edgeVecSize = 0\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:43.395] [puff::index::jointLog] [info] num keys = 22,651,680\n",
      "\u001b[00mfor info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000 \n",
      "[Building BooPHF]  100  %   elapsed:   0 min 2  sec   remaining:   0 min 0  sec\n",
      "Bitarray       118693184  bits (100.00 %)   (array + ranks )\n",
      "final hash             0  bits (0.00 %) (nb in final hash 0)\n",
      "\u001b[00m[2023-10-24 14:21:45.300] [puff::index::jointLog] [info] mphf size = 14.1493 MB\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:45.366] [puff::index::jointLog] [info] chunk size = 15,419,580\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:45.366] [puff::index::jointLog] [info] chunk 0 = [0, 15,419,580)\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:45.366] [puff::index::jointLog] [info] chunk 1 = [15,419,580, 30,839,130)\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:47.841] [puff::index::jointLog] [info] finished populating pos vector\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:47.841] [puff::index::jointLog] [info] writing index components\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:21:48.036] [puff::index::jointLog] [info] finished writing dense pufferfish index\n",
      "\u001b[00m[2023-10-24 14:21:48.064] [jLog] [info] done building index\n"
     ]
    }
   ],
   "source": [
    "# index the transcriptome\n",
    "!salmon index -t {OUTDIR}/chr22_txome/txome.fa -i {OUTDIR}/chr22_txome_index -k 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Server Response: Not Found\n",
      "### salmon (selective-alignment-based) v1.10.2\n",
      "### [ program ] => salmon \n",
      "### [ command ] => quant \n",
      "### [ geneMap ] => { ../results/20231004_benchmark/chr22_txome/txome_t2g.tsv }\n",
      "### [ index ] => { ../results/20231004_benchmark/chr22_txome_index }\n",
      "### [ libType ] => { A }\n",
      "### [ mates1 ] => { ../results/20231004_benchmark/chr22_reads/sample_01_1.fasta.gz }\n",
      "### [ mates2 ] => { ../results/20231004_benchmark/chr22_reads/sample_01_2.fasta.gz }\n",
      "### [ output ] => { ../results/20231004_benchmark/chr22_quant/sample_01 }\n",
      "### [ threads ] => { 8 }\n",
      "Logs will be written to ../results/20231004_benchmark/chr22_quant/sample_01/logs\n",
      "\u001b[00m[2023-10-24 14:28:04.195] [jointLog] [info] setting maxHashResizeThreads to 8\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.195] [jointLog] [info] Fragment incompatibility prior below threshold.  Incompatible fragments will be ignored.\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.195] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.195] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.195] [jointLog] [info] parsing read library format\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.195] [jointLog] [info] There is 1 library.\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.197] [jointLog] [info] Loading pufferfish index\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.197] [jointLog] [info] Loading dense pufferfish index.\n",
      "\u001b[00m-----------------------------------------\n",
      "| Loading contig table | Time = 152.68 ms\n",
      "-----------------------------------------\n",
      "size = 272917\n",
      "-----------------------------------------\n",
      "| Loading contig offsets | Time = 1.6033 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference lengths | Time = 25.491 us\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading mphf table | Time = 12.04 ms\n",
      "-----------------------------------------\n",
      "size = 30839160\n",
      "Number of ones: 272916\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 534\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 67.208 ms\n",
      "-----------------------------------------\n",
      "size = 30839160\n",
      "-----------------------------------------\n",
      "| Loading sequence | Time = 7.6951 ms\n",
      "-----------------------------------------\n",
      "size = 22651680\n",
      "-----------------------------------------\n",
      "| Loading positions | Time = 66.695 ms\n",
      "-----------------------------------------\n",
      "size = 33145561\n",
      "-----------------------------------------\n",
      "| Loading reference sequence | Time = 11.692 ms\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| Loading reference accumulative lengths | Time = 92.834 us\n",
      "-----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[00m[2023-10-24 14:28:04.520] [jointLog] [info] done\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.655] [jointLog] [info] Index contained 3,501 targets\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.656] [jointLog] [info] Number of decoys : 0\n",
      "\u001b[00m\u001b[00m[2023-10-24 14:28:04.974] [jointLog] [info] Automatically detected most likely library type as IU\n",
      "\u001b[32mprocessed\u001b[31m 500,000 \u001b[32mfragments\u001b[0m\n",
      "hits: 1,875,548, hits per frag:  3.96695"
     ]
    }
   ],
   "source": [
    "# quantify the reads with salmon\n",
    "# -g = File containing mapping of transcripts to genes\n",
    "\n",
    "r1_reads = sorted((OUTDIR / \"chr22_reads\").glob(\"*_1.fasta.gz\"))\n",
    "r2_reads = sorted((OUTDIR / \"chr22_reads\").glob(\"*_2.fasta.gz\"))\n",
    "\n",
    "for r1, r2 in zip(r1_reads, r2_reads):\n",
    "    sample = \"_\".join(r1.stem.split(\"_\")[0:2])\n",
    "    !salmon quant -g {OUTDIR}/chr22_txome/txome_t2g.tsv -i {OUTDIR}/chr22_txome_index -l A -1 {r1} -2 {r2} -o {OUTDIR}/chr22_quant/{sample} -p 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
